    "LOGISTIC REGRESSION (Sigmoid Function)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "b980b188-0497-43c6-aa79-4551d7aef32f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split #train_test_split class is imported to split our data in train and test data\n",
    "\n",
    "#We have a small datset so I will split the datasets 80/20\n",
    "#As we have a small imbalanced dataset I will use the stratify parameter to avoid bias\n",
    "X_train, X_test,y_train,y_test = train_test_split(X,y,test_size=0.2,random_state=42, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "8c9e7bdd-96b2-49ed-924c-1696530c31ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(488, 10)"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Lets check the shape our train and test datasets\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "2c637a07-e53e-45c5-9fcc-f21d44ee6601",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(123, 10)"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "0afe285e-54ac-41d5-a3c1-74e37adf1807",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(488,)"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "2cd86f96-e2ab-4af8-a138-654f36253aad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(123,)"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "2894623a-84bb-4a27-99d9-85ab9365d9de",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression #importing our Logistic Regression model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "113bdd10-f4d8-4190-a13f-690eab043ef5",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LogisticRegression(C=1.0,penalty='l1',solver='liblinear') #creating an instance of class Logistic Regression and setting our hyperparameters\n",
    "\n",
    "#C = 1.0: controls how much the model is penalized on large coefficents - C = 1.0 is the defult\n",
    "#penalty = 'l1' : can shrink some weights to zero, some of our independent variables do not have a strong correlation with the target variable so this will help with feature selection\n",
    "#solver='liblinear' : good for small datasets and support l1 (lasso)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "1e07e266-c717-4e01-bb1d-d1c04440b3b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(penalty='l1', solver='liblinear')"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#fit the model to our train data\n",
    "\n",
    "model.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "0435f02e-d1f6-4680-b2bb-496c0f3b59a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now our model has been trained on our data I will use Pickle to export our trained model and import it again to run on our test data\n",
    "#open a file, where you want to store the data\n",
    "\n",
    "import pickle\n",
    "\n",
    "with open('Loan_Data_Logistic_model.pkl','wb') as file:\n",
    "    #dump information to the file\n",
    "    pickle.dump(model,file)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "b4799e79-0a95-40dd-ad85-f3628a5edbff",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('Loan_Data_Logistic_model.pkl','rb') as file: #Loading our trained model that we dumped as a pkl file\n",
    "    loaded_model = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "ec01d758-ca6e-46d8-a9e7-8baac019ba4a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(penalty='l1', solver='liblinear')"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loaded_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "1b465561-38eb-4338-bd13-f1d8faef007b",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = loaded_model.score(X_test,y_test) #Run our trained model on our test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "943c7930-aebc-4ab8-9066-a64de6b9393f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.86%\n"
     ]
    }
   ],
   "source": [
    "#checking how accurate our model was on our test data\n",
    "from sklearn.metrics import accuracy_score \n",
    "\n",
    "y_pred_test = loaded_model.predict(X_test)\n",
    "\n",
    "acc = accuracy_score(y_test, y_pred_test)\n",
    "print(f'Accuracy: {acc:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "539c1445-1f6d-463c-8bdd-0dd5572dd5a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set score: 0.80%\n"
     ]
    }
   ],
   "source": [
    "#print the score on training and test set\n",
    "\n",
    "print(f'Training set score: {model.score(X_train,y_train):.2f}%') #accuracy of our model on our train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "a390b9e6-f66e-49c2-a785-c5bfa7f220c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Considering we have a very small dataset, I believe the model has done well and produced good reults."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "0d6516df-fbd9-48ab-a1b4-e4dc8ea1091c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lets try and use a model with a larger C value to decrease regularization and check our models accuracy\n",
    "\n",
    "model100 = LogisticRegression(C=100,penalty='l1',solver='liblinear')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "2cc16393-0e40-46e1-a593-ff533b039136",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_pred = model100.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "106ae302-9c66-4c7c-ab3e-a0d8a458074f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set score: 0.80%\n"
     ]
    }
   ],
   "source": [
    "print(f'Training set score: {train_pred.score(X_train,y_train):.2f}%') #accuracy of our model on our train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "9602180a-f400-448a-b57d-9ffbcf4a64cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Nothing has changed we still got 80%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "2ba09571-c1ad-476f-b542-be14807b1ee8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.56      0.72        39\n",
      "           1       0.83      1.00      0.91        84\n",
      "\n",
      "    accuracy                           0.86       123\n",
      "   macro avg       0.92      0.78      0.81       123\n",
      "weighted avg       0.89      0.86      0.85       123\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Visualize our data accuracy with a classifcation report \n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print(classification_report(y_test,y_pred_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "89b8ca13-c753-40fc-87e6-3caef6b97855",
   "metadata": {},
   "outputs": [],
   "source": [
    "#for Class 0 \n",
    "# Precision: 1.00 → Perfect when it predicted class 0\n",
    "# Recall: 0.56 → Only 56% of actual class 0s were correctly found.\n",
    "# F1: 0.72 → A bit of imbalance; model is cautious about predicting class 0.\n",
    "\n",
    "# Class 1\n",
    "# Precision: 0.83 → Sometimes predicts class 1 when it's not.\n",
    "# Recall: 1.00 → Caught all actual class 1 cases.\n",
    "# F1: 0.91 → Strong overall performance on this class.\n",
    "\n",
    "#Overall I am happy with the results of the model on our small dataset, we would a bigger dataset with less imbalance to increase the accuracy of this model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e6e9e7e-e286-4978-9e59-ee04b7ab40a8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
